---
title: "IGExtract"
author: "Brandon Taylor"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{IGExtract}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

IGExtract is an package which chunks text based on Elinor Ostrom's institutional
grammar. Each institutional document contains institutional statements. 
Institutional statements contain some of the following six components:

* Attribute: Characteristics of who the institutional statements apply to.
* oBject: Who receives the aim of the statement
* Deontic: One of "may", "may not", "must", or "must not"
* aIm: The action which the institutional statement is regulating
* Conditions: The conditions underwhich the statement applies
* Or else: Consequences if the statement is violated

To input chunked institutional documents, use a dataframe with the following
format:

* `document`: A unique name or ID for every instutional document.
* `text`: A fragement of text from the document
* `component`: one of ABDICO, if applicable. `NA` otherwise.
* `statement_ID`: A unique ID for each statement in a document, and for any
fragments of text between institutional statements.

All text from the original document should appear in order in the text field.

```{r, message = FALSE}
library(knitr)
library(dplyr)

chunked = data.frame(
  document = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1),
  text = c("Power plants", "must not", "ever", "pollute", "the air",
            "and also",
            "sewage plants", "must not", "ever", "pollute", "the water"),
  component = c("attribute", "deontic", NA, "aim", "object",
                NA,
                "attribute", "deontic", NA, "aim", "object"),
  statement_ID = c(1, 1, 1, 1, 1,
                   2,
                   3, 3, 3, 3, 3))
chunked %>% kable
```

This chunked data can be used as training data. Text which you wish to chunk
should use the following format:

* `document`:  A unique name or ID for every instutional document.
* `text`: The text of the document

```{r}
unchunked = data.frame(
  document = 2,
  text = "Chemical plants must not ever pollute the soil"
)

unchunked %>% kable
```

The first step is to tag parts of speech and institutional grammar components.
You need to include chunked and unchunked data together.

```{r, warning = FALSE}
library(IGExtract)

tags = tag(chunked, unchunked)

tags %>% head %>% kable
```

The next step is to build a feature set. It will return an chunked feature set and
an unchunked feature set.

`number_of_words` is the number of words to consider as distinct. Since most 
words in a text a rarely used, they do not contribute to a accuracy.

`word_window` is the number of words before and after the word to use to help
predict the tag.

`part_of_speech_window` is the number of parts of speech of words before and 
after the word to help predict the part of speech.

```{r, warning = FALSE}
my_features = features(tags,
                       number_of_words = 3,
                       word_window = 3,
                       part_of_speech_window = 3)
```

You might notice for real data that some tags are for more common than others.
For example, in many institutional documents, words outside any statement are
by far the most common. To balance the data such that there is an equal number
of data points for each tag, use `balance`.

We need to predict these tags for the unchunked text. Build a classified with
chunker.

```{r}
my_chunker = chunker(my_features$chunked)
```

We can use this chunker to chunk the unchunked text.

```{r}
kable(my_chunker %>% chunk(my_features$unchunked))
```

If we want to know how accurate the a chunker is, we can validate it by
splitting up the chunked feature set into training and testing datasets. 
`fraction` is the fraction of words in the training dataset. It defaults to 0.5.

```{r}
set.seed(1)
my_training_and_testing = training_and_testing(my_features$chunked)
training_chunker = chunker(my_training_and_testing$training)
validate(training_chunker, my_training_and_testing$testing) %>% kable
```

The rows represent actual tags, and columns are predicted tags. The line of 1s
across the diagonals represents words which were correctly tagged. All words 
were tagged correctly.
